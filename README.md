# ğŸ“Œ Data Loading with Incremental Loading

## ğŸš€ Overview
This project demonstrates **incremental data loading** using Azure Synapse, Azure Data Factory, and SQL. The pipeline loads data from five tables while tracking changes using a **Watermark Table**.

## ğŸ—ï¸ Schema Definition
We have created five tables:
- **Customer** (Delta Column: `Customer_ID`)
- **Employee** (Delta Column: `Updated_At`)
- **Product** (Delta Column: `Product_ID`)
- **Orders** (Delta Column: `Order_Date`)
- **Sales** (Delta Column: `Transaction_Date`)

## ğŸ“Š Watermark Table
The Watermark Table helps manage incremental loads:
- **SchemaName** - Stores schema names (e.g., `dbo`).
- **TableName** - Stores table names (e.g., `Customer`).
- **FolderPath** - Defines the storage location for processed data.
- **LPV (Last Processed Value)** - Stores the latest processed value for tracking.
- **DeltaColumn** - Specifies the column used for incremental checks.

## ğŸ”„ Pipeline Steps
1. **Lookup Activity** - Reads the Watermark Table.
2. **Foreach Activity** - Iterates through tables.
3. **Lookup Max Value** - Gets the latest delta column value.
4. **IF Condition** - Compares LPV with Max Value to determine if new data exists.
5. **Copy Activity** - Loads new data to ADLS in **Parquet format**.
6. **Stored Procedure Activity** - Updates LPV in the Watermark Table.

## ğŸ“‚ Folder Structure
```
ğŸ“ GitHub-Repo
â”‚â”€â”€ ğŸ“„ README.md
â”‚â”€â”€ ğŸ“‚ Data
â”‚   â”œâ”€â”€ customer_data.csv
â”‚   â”œâ”€â”€ product_data.csv
â”‚   â”œâ”€â”€ orders_data.csv
â”‚   â”œâ”€â”€ sales_data.csv
â”‚â”€â”€ ğŸ“‚ SQL
â”‚   â”œâ”€â”€ schema.sql
â”‚   â”œâ”€â”€ insert_data.sql
â”‚   â”œâ”€â”€ watermark_table.sql
â”‚   â”œâ”€â”€ update_watermark_proc.sql
â”‚â”€â”€ ğŸ“‚ Pipelines
â”‚   â”œâ”€â”€ incremental_pipeline.json
â”‚â”€â”€ ğŸ“‚ Docs
â”‚   â”œâ”€â”€ Project_Documentation.pdf
```

## âš¡ Running the Pipeline
1. Open **Azure Synapse Workspace** and create a new pipeline.
2. Use Lookup Activity to read the Watermark Table.
3. Configure parameters (`schema_name`, `table_name`).
4. Run **debug mode** and validate outputs in ADLS.

## ğŸ“ Additional Notes
- Ensure the SQL schema matches the expected data.
- Use **Synapse Linked Service** to connect to Azure SQL.
- The pipeline prevents empty file creation by checking `IF LPV < MAX(DeltaColumn)`.
